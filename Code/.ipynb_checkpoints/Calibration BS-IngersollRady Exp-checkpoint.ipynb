{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qmcpy.true_measure.uniform import Uniform\n",
    "from qmcpy.discrete_distribution.halton.halton import Halton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import time\n",
    "_tstart_stack = []\n",
    "\n",
    "def tic():\n",
    "    _tstart_stack.append(time.time())\n",
    "\n",
    "def toc(fmt=\"Elapsed: %s s\"):\n",
    "    print(fmt % (time.time() - _tstart_stack.pop()))\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The price is given by Two Parts\n",
    "\n",
    "- First part - easy to implement\n",
    "- Second part - complex - Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Black Scholes formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def cnd_numba(d):\n",
    "    \"\"\"cdf of Normal distribution\"\"\"\n",
    "    \n",
    "    A1 = 0.31938153\n",
    "    A2 = -0.356563782\n",
    "    A3 = 1.781477937\n",
    "    A4 = -1.821255978\n",
    "    A5 = 1.330274429\n",
    "    RSQRT2PI = 0.39894228040143267793994605993438\n",
    "    K = 1.0 / (1.0 + 0.2316419 * math.fabs(d))\n",
    "    ret_val = (RSQRT2PI * math.exp(-0.5 * d * d) *\n",
    "               (K * (A1 + K * (A2 + K * (A3 + K * (A4 + K * A5))))))\n",
    "    if d > 0:\n",
    "        ret_val = 1.0 - ret_val\n",
    "    return ret_val\n",
    "\n",
    "@jit\n",
    "def black_scholes_numba(stockPrice, optionStrike,\n",
    "                        optionYears, Riskfree, Volatility):\n",
    "    \"\"\"Standard BS formuls\"\"\"\n",
    "\n",
    "    S = stockPrice\n",
    "    X = optionStrike\n",
    "    T = optionYears\n",
    "    R = Riskfree\n",
    "    V = Volatility\n",
    "\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / X) + (R + 0.5 * V * V) * T) / (V * sqrtT)\n",
    "    d2 = d1 - V * sqrtT\n",
    "    cndd1 = cnd_numba(d1)\n",
    "    cndd2 = cnd_numba(d2)\n",
    "\n",
    "    expRT = math.exp((-1. * R) * T)\n",
    "    callResult = (S * cndd1 - X * expRT * cndd2)\n",
    "\n",
    "    return callResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Part: No Jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def rady_numba(s, k, t, sigma0, l0, u0):\n",
    "    return black_scholes_numba((1-k/u0)*(s-l0), \n",
    "                                (k-l0)*(1-s/u0),\n",
    "                                t, \n",
    "                                0, \n",
    "                                (1 - l0 / u0) * sigma0) * u0 / (u0-l0)\n",
    "\n",
    "@jit\n",
    "def enlarge_rady_numba(s, k, t, sigma0, l0, u0):\n",
    "    if 0 < k <= l0:\n",
    "        return s - k\n",
    "    elif k >= u0:\n",
    "        return 0\n",
    "    elif l0 < k < u0:\n",
    "        return rady_numba(s, k, t, sigma0, l0, u0)\n",
    "    \n",
    "@jit\n",
    "def no_jump_price_numba(s, k, t, rd, rf, sigma0, l0, u0, lamb, kappa):\n",
    "    h_t = lamb * kappa * t\n",
    "    k_star = k * np.exp(-(rd-rf)*t) / np.exp(-h_t)\n",
    "    return np.exp(- rf * t) * np.exp(-h_t) * enlarge_rady_numba(s, k_star, t, sigma0, l0, u0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Part: With Jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def normal_pdf_numba(x):\n",
    "    \"\"\"pdf of Normal distributio\"\"\"\n",
    "    \n",
    "    return np.exp(-0.5*x**2)/2.5066282746310002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def implied_density_numba(x, s, l0, u0, sigma0, t):\n",
    "    \"\"\"Implied density function at tau\"\"\"\n",
    "    sigmat = (1 - l0 / u0) * sigma0  * t**0.5\n",
    "    term1 = ((u0 - s) * (u0 - l0)) / (sigmat * (u0-x)**2 * (x-l0))\n",
    "    term2 = (np.log(((s-l0)*(1-x/u0))/((x-l0)*(1-s/u0))) - 0.5 * sigmat**2) / sigmat\n",
    "    return term1 * normal_pdf_numba(term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def mc_kernel(x, tau_s, s,k,t,rd,rf,sigma0,sigma1,lamb,kappa,l0,u0):\n",
    "    \"\"\"price kernel: the integrand of double integral\"\"\"\n",
    "    \n",
    "    term1 = black_scholes_numba(x*np.exp(-lamb*kappa*tau_s)*(1+kappa), \n",
    "                                    k*np.exp(-(rd-rf)*t),\n",
    "                                    t-tau_s, \n",
    "                                    0, \n",
    "                                    sigma1)\n",
    "    term2 = implied_density_numba(x, s, l0, u0, sigma0, tau_s)\n",
    "    term3 = lamb * np.exp(-lamb * tau_s)\n",
    "    return term1 * term2 * term3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price1 + Price2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def first_price_numba(s,k,t,rd,rf,sigma0,lamb,kappa,l0,u0):\n",
    "    \"\"\"First price: extend Rady\"\"\"\n",
    "    return no_jump_price_numba(s, k, t, rd, rf, sigma0, l0, u0, lamb, kappa) * np.exp(-lamb*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def second_price_qmc_numba(s,k,t,rd,rf,sigma0,sigma1,lamb,kappa,l0,u0):\n",
    "    \"\"\"second price given by Quasi Monte Carlo\n",
    "        NMAX, Y_SAMP, TAU_SAMP,\n",
    "    \"\"\"\n",
    "    cum_bs = 0\n",
    "    for y_i, tau_i in zip(Y_SAMP, TAU_SAMP):\n",
    "        cum_bs += mc_kernel(y_i, tau_i, s,k,t,rd,rf,sigma0,sigma1,lamb,kappa,l0,u0)\n",
    "\n",
    "    qmc_price = np.exp(-rf*t) * cum_bs / NMAX * (u0-l0) * t\n",
    "    return qmc_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def qmc_price_numba(s,k,t,rd,rf,sigma0,sigma1,lamb,kappa,l0,u0):\n",
    "    \"\"\"final price\"\"\"\n",
    "    price1 = first_price_numba(s,k,t,rd,rf,sigma0,lamb,kappa,l0,u0)\n",
    "    price2 = second_price_qmc_numba(s,k,t,rd,rf,sigma0,sigma1,lamb,kappa,l0,u0)\n",
    "    return price1 + price2\n",
    "qmc_price_vect = np.vectorize(qmc_price_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate samples : Fixed after sampling, always be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Enlarge_Factor', Enlarge_Factor) # according to real data\n",
    "\n",
    "# given the fixed paras when sampling\n",
    "L0_SAMP = 7.75*(1-Enlarge_Factor)\n",
    "U0_SAMP = 7.85*(1+Enlarge_Factor)\n",
    "\n",
    "print('7.75-->', L0_SAMP,'\\n7.85-->', U0_SAMP)\n",
    "T_SAMP = 0.5 # 6 months\n",
    "\n",
    "NMAX = 10e5 # numbers of sample\n",
    "\n",
    "# 2-d Uniform, random seed = 7\n",
    "unf = Uniform(Halton(2, seed=1), lower_bound=0, upper_bound=1)\n",
    "\n",
    "# lenth of uniform rv is n_max\n",
    "unf_sample = unf.gen_samples(n_min=0, n_max=NMAX)\n",
    "print('Numbers of Sample:', NMAX)\n",
    "\n",
    "# prepare the data\n",
    "Y_SAMP = L0_SAMP + (U0_SAMP-L0_SAMP) * unf_sample[:,0]\n",
    "TAU_SAMP = T_SAMP * unf_sample[:,1]\n",
    "\n",
    "print('Sampling finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import root, brentq, minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def garman_kohlhagen_numba(s, k, t, rd, rf, sigma):\n",
    "\n",
    "    sqrt = math.sqrt(t)\n",
    "    d1 = (math.log(s / k) + (rd-rf + 0.5 * sigma * sigma) * t) / (sigma * sqrt)\n",
    "    d2 = d1 - sigma * sqrt\n",
    "    cndd1 = cnd_numba(d1)\n",
    "    cndd2 = cnd_numba(d2)\n",
    "\n",
    "    exprdt = math.exp((-1. * rd) * t)\n",
    "    exprft = math.exp((-1. * rf) * t)\n",
    "    callresult = (s *exprft* cndd1 - k * exprdt * cndd2)\n",
    "\n",
    "    return callresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impliedvol_func(s, k, t, rd, rf, price):\n",
    "    def root_func(x):\n",
    "        return garman_kohlhagen_numba(s, k, t, rd, rf, x) - price\n",
    "    result = 0\n",
    "    try:\n",
    "        result = brentq(root_func, 0.001, 30)\n",
    "    except Exception:\n",
    "        print('There is a problem here with brentq')\n",
    "        result = root(root_func, 0.2).x[0]\n",
    "    return result\n",
    "Impliedvol = np.vectorize(impliedvol_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_model(x, s, k, t, rd, rf, l0=L0_SAMP, u0=U0_SAMP):\n",
    "    \"\"\"\n",
    "    x[0]: sigma0\n",
    "    x[1]: sigma1\n",
    "    x[2]: lamb\n",
    "    x[3]: kappa    \n",
    "    \"\"\"\n",
    "    price = qmc_price_vect(s, k, t, rd, rf, x[0], x[1], x[2], x[3], l0, u0)\n",
    "    return Impliedvol(s, k, t, rd, rf, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with sigma lower bar\n",
    "def Fit_BF_sigmalow(OBJ, INPUT, GUESS, S, T, Rd, Rf, Verbose = 2):\n",
    "    \n",
    "    # By assumption OBJ = [SxP, SxP, SATM, SxC, SxC]\n",
    "    # And INPUT = [KxP, KxP, KATM, KxC, KxC]\n",
    "\n",
    "    # we first get the dimension\n",
    "    n = OBJ.size\n",
    "\n",
    "    BOUNDS = ([0.1,  OBJ[2], 0.0001, -0.8], \n",
    "              [500,  30,     1 / T,   0.8])\n",
    "    \n",
    "    # Check that the Guess is correct\n",
    "    GUESS[1] = np.maximum(GUESS[1], OBJ[2]) # for sigma upper [1]\n",
    "    GUESS[0] = np.minimum(GUESS[0], 7.8*OBJ[2]/0.0003185*0.5) # for sigma lower\n",
    "\n",
    "    ###\n",
    "\n",
    "    def fun(x, k, y):\n",
    "        z = x\n",
    "        term = np.empty(n)\n",
    "        for i in range(n):\n",
    "            term[i] = (sigma_model(z, S, k[i], T, Rd, Rf) - y[i])\n",
    "        return term\n",
    "\n",
    "    res_lsq = least_squares(fun, \n",
    "                            GUESS, \n",
    "                            loss = 'cauchy', \n",
    "                            bounds=BOUNDS, \n",
    "                            args = (INPUT, OBJ), \n",
    "                            verbose = Verbose,\n",
    "                            max_nfev=180\n",
    "                           )\n",
    "    x = res_lsq.x\n",
    "    s = sigma_model(x, S, INPUT, T, Rd, Rf)\n",
    "    \n",
    "    # 20190816 modify Errors\n",
    "    o1 = OBJ[0]\n",
    "    o2 = OBJ[1]\n",
    "    o3 = OBJ[2]\n",
    "    o4 = OBJ[3]\n",
    "    o5 = OBJ[4]\n",
    "\n",
    "    c1 = s[0]\n",
    "    c2 = s[1]\n",
    "    c3 = s[2]\n",
    "    c4 = s[3]\n",
    "    c5 = s[4]\n",
    "    \n",
    "    # mean squared error\n",
    "    e1 = ((o1 - c1)  / o1) ** 2\n",
    "    e2 = ((o2 - c2)  / o2) ** 2\n",
    "    e3 = ((o3 - c3)  / o3) ** 2\n",
    "    e4 = ((o4 - c4)  / o4) ** 2\n",
    "    e5 = ((o5 - c5)  / o5) ** 2\n",
    "\n",
    "    # 20190822 mean error\n",
    "    m1 = (np.abs(o1 - c1)  / o1)\n",
    "    m2 = (np.abs(o2 - c2)  / o2)\n",
    "    m3 = (np.abs(o3 - c3)  / o3)\n",
    "    m4 = (np.abs(o4 - c4)  / o4)\n",
    "    m5 = (np.abs(o5 - c5)  / o5)\n",
    "\n",
    "    rmse = ((e1+e2+e3+e4+e5) / 5) ** 0.5\n",
    "    mse = (m1+m2+m3+m4+m5) / 5 \n",
    "\n",
    "    # 20190816 two errors to one rmse\n",
    "    # 20190822 rmse, error, errorpa\n",
    "    error = np.linalg.norm(OBJ-s)\n",
    "    errorpa = error / OBJ.mean() * 100\n",
    "    return res_lsq.x, s, rmse, mse, error, errorpa, res_lsq.nfev, res_lsq.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(row):\n",
    "    global GUESS\n",
    "    \n",
    "    S = row['S']\n",
    "    Rd = row['Rd']\n",
    "    Rf = row['Rf']\n",
    "    T = row['T']\n",
    "    \n",
    "    S10P = row['S10P']\n",
    "    S25P = row['S25P']\n",
    "    SATM = row['SATM']\n",
    "    S25C = row['S25C']\n",
    "    S10C = row['S10C']\n",
    "    \n",
    "    K10P = row['K10P']\n",
    "    K25P = row['K25P']\n",
    "    KATM = row['KATM']\n",
    "    K25C = row['K25C']\n",
    "    K10C = row['K10C']\n",
    "    \n",
    "    OBJ = np.array([S10P, S25P, SATM, S25C, S10C])\n",
    "    INPUT = np.array([K10P, K25P, KATM, K25C, K10C])\n",
    "    \n",
    "    res_lsq_x, s,rmse,mse, error, errorpa, res_lsq_nfev, res_lsq_status = Fit_BF_sigmalow(OBJ, INPUT, GUESS, S, T, Rd, Rf)\n",
    "    print('Data Now is:\\n%s\\nGUESS = %s\\n error = %f\\n errorpa = %f' %(row,GUESS, error, errorpa))\n",
    "    \n",
    "    GUESS = res_lsq_x\n",
    "\n",
    "    return pd.Series({\n",
    "        'sigma0': res_lsq_x[0],\n",
    "        'sigma1': res_lsq_x[1],\n",
    "        'lamb': res_lsq_x[2],\n",
    "        'kappa': res_lsq_x[3],\n",
    "        \n",
    "        'sS10P': s[0],\n",
    "        'sS25P': s[1],\n",
    "        'sSATM': s[2],\n",
    "        'sS25C': s[3],\n",
    "        'sS10C': s[4],\n",
    "        \n",
    "        'rmse': rmse,\n",
    "        'mse': mse,\n",
    "        'Err': error,\n",
    "        'ErrPa': errorpa,\n",
    "        'Nfev': res_lsq_nfev,\n",
    "        'Status': res_lsq_status\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6M\n",
    "df = pd.read_pickle('./../Data/Data_for_Calibration/USDHKD0608_6M_for_Calibration_Average.pkl')\n",
    "del df['SEMP'] # delet semp which is ueseless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmax = df['Rd'].max()\n",
    "rdmin = df['Rd'].min()\n",
    "\n",
    "rfmax = df['Rf'].max()\n",
    "rfmin = df['Rf'].min()\n",
    "\n",
    "fct = max(abs(rdmax-rfmin), abs(rfmax-rdmin))\n",
    "fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_6months = 0.5\n",
    "Enlarge_Factor = max(1-np.exp(-fct*T_6months),np.exp(fct*T_6months)-1)\n",
    "print('Enlarge_Factor', Enlarge_Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nan value\n",
    "df = df.dropna().loc['2014':]\n",
    "\n",
    "df.head() # show and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: 2014-01-02 00:00:00, dtype: object\n",
    "# GUESS = [ 4.179  0.094  0.107 -0.011]\n",
    "GUESS = np.array([4.179, 0.094, 0.107, -0.011])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "result_df = df.apply(func, axis = 1)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed: 36361.29989647865 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedf = df.join(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
